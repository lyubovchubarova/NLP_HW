{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 89,
   "metadata": {},
   "outputs": [],
   "source": [
    "import requests\n",
    "from bs4 import BeautifulSoup\n",
    "import string\n",
    "import nltk\n",
    "import string\n",
    "from nltk.corpus import stopwords\n",
    "from nltk.tokenize import word_tokenize\n",
    "import re\n",
    "from pymorphy2 import MorphAnalyzer\n",
    "from nltk.util import ngrams\n",
    "from collections import Counter\n",
    "import csv\n",
    "from sklearn.metrics import accuracy_score"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "К сожалению, у меня не получилось спарсить отзывы. \n",
    "Отзовик не дает доступ к исходному коду, на IRecommend есть ограничение в 10 отзывов за раз. Даже прокси не помогает. Ниже приведен написанный парсер для IRecommend. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 213,
   "metadata": {},
   "outputs": [],
   "source": [
    "#место для ссылок и метаинфы\n",
    "#ссылки на плохие отзывы, хорошие отзывы и какое-то количество рандомных\n",
    "bad_link = 'https://irecommend.ru/content/balzam-opolaskivatel-bioaktivnyi-balzam-opolaskivatel-khors-fors-loshadinaya-sila?ft[r]=0'\n",
    "good_link = 'https://irecommend.ru/content/balzam-opolaskivatel-bioaktivnyi-balzam-opolaskivatel-khors-fors-loshadinaya-sila?ft[r]=1&new=1'\n",
    "random_link = 'https://irecommend.ru/content/balzam-opolaskivatel-bioaktivnyi-balzam-opolaskivatel-khors-fors-loshadinaya-sila'\n",
    "\n",
    "#множества слов, встречающихся только в плохих и только в хороших отзывах\n",
    "bad_words = []\n",
    "good_words = []\n",
    "\n",
    "#тексты отзывов\n",
    "bad_reviews = []\n",
    "good_reviews = []\n",
    "random_reviews = []\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "metadata": {},
   "outputs": [],
   "source": [
    "#функция для препроцессинга\n",
    "#чистим от знаков препинания, стоп-слов, лемматизируем\n",
    "def preprocess(review):\n",
    "    review = review.replace('\\n', '').lower()\n",
    "    \n",
    "    for elem in punct:\n",
    "        if elem in review:\n",
    "            review = review.replace(elem, ' ')\n",
    "    re.sub(r' {2,}', ' ', review)\n",
    "    \n",
    "    word_tokens = word_tokenize(review)\n",
    "    review = ''\n",
    "    for word in word_tokens:\n",
    "        if word not in stop_words:\n",
    "            word = morph.parse(word)[0].normal_form\n",
    "            review += word + ' '\n",
    "        \n",
    "    return review"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 229,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_data(link, reviews_list, i):\n",
    "    response = requests.get(link)\n",
    "    soup = BeautifulSoup(response.text)\n",
    "    print(response)\n",
    "    \n",
    "    #находим все ссылки на конкретные отзывы\n",
    "    review_data = soup.find_all('div', {'class': 'reviewTitle'})\n",
    "    \n",
    "    source_links = []\n",
    "    for elem in review_data:\n",
    "        elem = elem.find('a')\n",
    "        try:\n",
    "            source_links.append(elem.get('href'))\n",
    "        except AttributeError as e:\n",
    "            pass\n",
    "        \n",
    "    if len(source_links) > i:\n",
    "        sourse_links = source_links[:i]\n",
    "    \n",
    "    #собираем текст отзыва, делаем препроцессинг\n",
    "    for adress in source_links:\n",
    "        site = 'https://irecommend.ru' + adress\n",
    "        response = requests.get(site)\n",
    "        soup = BeautifulSoup(response.text)\n",
    "        review = soup.find('div', {'class':'views-field-teaser reviewText'})\n",
    "        review = preprocess(review)\n",
    "        reviews_list.append(review)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 230,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<Response [521]>\n",
      "<Response [521]>\n",
      "<Response [521]>\n"
     ]
    }
   ],
   "source": [
    "get_data(bad_link, bad_reviews, 100)\n",
    "get_data(good_link, good_reviews, len(bad_reviews))\n",
    "get_data(random_link, random_reviews, 10)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Я нашла датасет с отзывами на женскую одежду и аксессуары, буду брать данные оттуда. Они размечены как положительные/отрицательные. Положительные - 4-5 звезд, отрицательные - 1-2 звезды. Еще кажется, что это данные с алиэкспресса. Это, наверное, может как-то повлиять."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "metadata": {},
   "outputs": [],
   "source": [
    "negative_raw = []\n",
    "positive_raw = []\n",
    "\n",
    "with open('women-clothing-accessories.csv', encoding = 'utf-8') as f:\n",
    "    reader = csv.reader(f)\n",
    "    for row in reader:\n",
    "        row = row[0].split(';')\n",
    "        try:\n",
    "            if row[1] == 'negative':\n",
    "                negative_raw.append(row[0])\n",
    "            if row[1] == 'positive':\n",
    "                positive_raw.append(row[0])\n",
    "        except IndexError as e:\n",
    "            pass"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 51,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Wall time: 0 ns\n"
     ]
    }
   ],
   "source": [
    "%time\n",
    "\n",
    "negative = []\n",
    "positive = []\n",
    "\n",
    "morph = MorphAnalyzer()\n",
    "punct = string.punctuation\n",
    "stop_words = set(stopwords.words('russian'))\n",
    "\n",
    "for review in negative_raw:\n",
    "    negative.append(preprocess(review))\n",
    "    \n",
    "for review in positive_raw:\n",
    "    positive.append(preprocess(review))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 61,
   "metadata": {},
   "outputs": [],
   "source": [
    "negative = ''.join(negative)\n",
    "negative = word_tokenize(negative)\n",
    "n = set(negative)\n",
    "               \n",
    "positive = ''.join(positive)\n",
    "positive = word_tokenize(positive)\n",
    "p = set(positive)\n",
    "\n",
    "only_positive = p.difference(n) # слова, которые есть только в позитивных отзывах\n",
    "only_negative = n.difference(p) # слова, которые есть только в негативных отзывах\n",
    "\n",
    "negative = dict(Counter(negative))\n",
    "negative_clear = [] \n",
    "for elem in negative:\n",
    "    if elem in only_negative and negative[elem] > 2:\n",
    "        negative_clear.append(elem)\n",
    "        \n",
    "positive = dict(Counter(positive))\n",
    "positive_clear = []\n",
    "for elem in positive:\n",
    "    if elem in only_positive and positive[elem] > 2:\n",
    "        positive_clear.append(elem)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Итого, у нас есть списки не особо редких(больше двух вхождений) слов, котрые встречаются только в положительных и только в отрицательных отзывах на женскую одежду. Я скопировала с IRecommend 10 отзывов на женские чулки, блузки и штаны - разной тональности и на них буду проверять."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 80,
   "metadata": {},
   "outputs": [],
   "source": [
    "gold = []\n",
    "some_reviews = []\n",
    "\n",
    "with open('some_reviews.txt', encoding = 'utf-8') as f:\n",
    "    text = f.read()\n",
    "    \n",
    "text = text.split('\\n--\\n')\n",
    "for elem in text:\n",
    "    elem = elem.split(':\\n')\n",
    "    gold.append(elem[0])\n",
    "    some_reviews.append(preprocess(elem[1]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 85,
   "metadata": {},
   "outputs": [],
   "source": [
    "results = []\n",
    "\n",
    "for review in some_reviews:\n",
    "    good_count = 0\n",
    "    bad_count = 0\n",
    "    review = word_tokenize(review)\n",
    "    for word in review:\n",
    "        if word in positive_clear:\n",
    "            good_count += 1\n",
    "        if word in negative_clear:\n",
    "            bad_count += 1\n",
    "    if bad_count > good_count:\n",
    "        results.append('negative')\n",
    "    elif bad_count < good_count:\n",
    "        results.append('positive')\n",
    "    else:\n",
    "        results.append('no result')\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 87,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.5"
      ]
     },
     "execution_count": 87,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "accuracy_score(gold, results)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
